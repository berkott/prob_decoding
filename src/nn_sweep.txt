Iteration 0, Train Loss [0.5944721102714539, 0.5410407185554504], Test Loss [0.5004445910453796, 0.5901420712471008]
Iteration 100, Train Loss [0.12509800493717194, 0.1264597624540329], Test Loss [0.8043677806854248, 1.0448957681655884]
Iteration 200, Train Loss [0.0837201327085495, 0.0924021527171135], Test Loss [0.9112178087234497, 1.15314781665802]
Iteration 300, Train Loss [0.06218287721276283, 0.0765242949128151], Test Loss [0.9790818691253662, 1.240693211555481]
Iteration 400, Train Loss [0.05538306385278702, 0.06402987986803055], Test Loss [1.002264142036438, 1.2891842126846313]
Iteration 500, Train Loss [0.0548965260386467, 0.05688299611210823], Test Loss [1.0179791450500488, 1.323664665222168]
Iteration 600, Train Loss [0.04195024073123932, 0.05960589274764061], Test Loss [1.0555238723754883, 1.3622291088104248]
Iteration 700, Train Loss [0.03650346398353577, 0.04371916502714157], Test Loss [1.0782781839370728, 1.4238998889923096]
Iteration 800, Train Loss [0.03418637812137604, 0.04787474125623703], Test Loss [1.084261178970337, 1.4362772703170776]
Iteration 900, Train Loss [0.03158937394618988, 0.03860028088092804], Test Loss [1.0934985876083374, 1.4842422008514404]
Iteration 1000, Train Loss [0.03235194459557533, 0.03664995729923248], Test Loss [1.1087459325790405, 1.5116416215896606]
Iteration 1100, Train Loss [0.029367852956056595, 0.036106087267398834], Test Loss [1.117733359336853, 1.547770619392395]
Iteration 1200, Train Loss [0.025692259892821312, 0.030834386125206947], Test Loss [1.1381372213363647, 1.594183087348938]
Iteration 1300, Train Loss [0.026230759918689728, 0.029522666707634926], Test Loss [1.1476399898529053, 1.6229242086410522]
Iteration 1400, Train Loss [0.024266958236694336, 0.033965520560741425], Test Loss [1.1423381567001343, 1.6093339920043945]
Iteration 1500, Train Loss [0.022123189643025398, 0.0262436605989933], Test Loss [1.159359097480774, 1.660051941871643]
Iteration 1600, Train Loss [0.02639046683907509, 0.02675498090684414], Test Loss [1.1627799272537231, 1.674364447593689]
Iteration 1700, Train Loss [0.021264929324388504, 0.024562951177358627], Test Loss [1.1625491380691528, 1.6896857023239136]
Iteration 1800, Train Loss [0.019977549090981483, 0.02333579584956169], Test Loss [1.1773051023483276, 1.7285748720169067]
Iteration 1900, Train Loss [0.019611701369285583, 0.02286573313176632], Test Loss [1.1868231296539307, 1.7615516185760498]
Iteration 2000, Train Loss [0.02166558802127838, 0.026030855253338814], Test Loss [1.1851799488067627, 1.7648913860321045]
Iteration 0, Train Loss [0.5955275297164917, 0.5414711236953735], Test Loss [0.49553757905960083, 0.5895822048187256]
Iteration 100, Train Loss [0.05747637525200844, 0.060502029955387115], Test Loss [0.8566344976425171, 1.005110740661621]
Iteration 200, Train Loss [0.02724100649356842, 0.03225644677877426], Test Loss [0.9299916625022888, 1.141136884689331]
Iteration 300, Train Loss [0.017482060939073563, 0.019770411774516106], Test Loss [0.9523278474807739, 1.2198431491851807]
Iteration 400, Train Loss [0.012436202727258205, 0.014198868535459042], Test Loss [0.9795003533363342, 1.281459093093872]
Iteration 500, Train Loss [0.011267914436757565, 0.011021627113223076], Test Loss [0.9827367663383484, 1.3150510787963867]
Iteration 600, Train Loss [0.008292846381664276, 0.008235386572778225], Test Loss [0.9959650039672852, 1.3513189554214478]
Iteration 700, Train Loss [0.008529827930033207, 0.00855926238000393], Test Loss [0.9999735951423645, 1.3611834049224854]
Iteration 800, Train Loss [0.0061408160254359245, 0.005570726469159126], Test Loss [1.0132477283477783, 1.3801708221435547]
Iteration 900, Train Loss [0.006742655299603939, 0.00576686579734087], Test Loss [1.0226504802703857, 1.4001213312149048]
Iteration 1000, Train Loss [0.005194646771997213, 0.004177124705165625], Test Loss [1.0310194492340088, 1.4154891967773438]
Iteration 1100, Train Loss [0.005960260052233934, 0.004841229412704706], Test Loss [1.0332765579223633, 1.4142632484436035]
Iteration 1200, Train Loss [0.005152837373316288, 0.0036880262196063995], Test Loss [1.0417314767837524, 1.417912244796753]
Iteration 1300, Train Loss [0.005590176209807396, 0.0035281928721815348], Test Loss [1.0372354984283447, 1.4200259447097778]
Iteration 1400, Train Loss [0.004048830829560757, 0.005564546212553978], Test Loss [1.0477536916732788, 1.4232732057571411]
Iteration 1500, Train Loss [0.006298385560512543, 0.0055131129920482635], Test Loss [1.0430474281311035, 1.4181793928146362]
Iteration 1600, Train Loss [0.005085761658847332, 0.0025209293235093355], Test Loss [1.0515573024749756, 1.4305822849273682]
Iteration 1700, Train Loss [0.0032526343129575253, 0.0023092026822268963], Test Loss [1.0538028478622437, 1.4275668859481812]
Iteration 1800, Train Loss [0.0030362564139068127, 0.0018427686300128698], Test Loss [1.057313323020935, 1.4276721477508545]
Iteration 1900, Train Loss [0.0029132335912436247, 0.0036311564035713673], Test Loss [1.05022132396698, 1.42123281955719]
Iteration 2000, Train Loss [0.0022321133874356747, 0.001319186296314001], Test Loss [1.0606416463851929, 1.4271528720855713]
Iteration 0, Train Loss [0.590750515460968, 0.54010409116745], Test Loss [0.49654942750930786, 0.5906362533569336]
Iteration 100, Train Loss [0.04078923165798187, 0.03944317623972893], Test Loss [0.8626962304115295, 1.0259947776794434]
Iteration 200, Train Loss [0.01825522817671299, 0.01726836897432804], Test Loss [0.9032878875732422, 1.1166372299194336]
Iteration 300, Train Loss [0.011811788193881512, 0.008213049732148647], Test Loss [0.9216293096542358, 1.1479779481887817]
Iteration 400, Train Loss [0.006612402852624655, 0.005485673435032368], Test Loss [0.9283162355422974, 1.1750820875167847]
Iteration 500, Train Loss [0.005790290422737598, 0.0035733880940824747], Test Loss [0.9290429949760437, 1.186354637145996]
Iteration 600, Train Loss [0.007304381113499403, 0.0030210944823920727], Test Loss [0.92477947473526, 1.1958035230636597]
Iteration 700, Train Loss [0.00374322640709579, 0.002090117894113064], Test Loss [0.9287025332450867, 1.198682188987732]
Iteration 800, Train Loss [0.004873307887464762, 0.002253373619168997], Test Loss [0.9208428263664246, 1.2030913829803467]
Iteration 900, Train Loss [0.005782364401966333, 0.0023729531094431877], Test Loss [0.920100748538971, 1.2053760290145874]
Iteration 1000, Train Loss [0.003541241865605116, 0.0017188397468999028], Test Loss [0.9180376529693604, 1.1997977495193481]
Iteration 1100, Train Loss [0.00577861163765192, 0.002382394392043352], Test Loss [0.9171497821807861, 1.1987321376800537]
Iteration 1200, Train Loss [0.0020048716105520725, 0.001678094151429832], Test Loss [0.9155098795890808, 1.1972346305847168]
Iteration 1300, Train Loss [0.002248356817290187, 0.00159292237367481], Test Loss [0.9137227535247803, 1.196720838546753]
Iteration 1400, Train Loss [0.002610250376164913, 0.001294740941375494], Test Loss [0.9110528826713562, 1.2010414600372314]
Iteration 1500, Train Loss [0.00201797834597528, 0.001774010481312871], Test Loss [0.913620114326477, 1.202199101448059]
Iteration 1600, Train Loss [0.0026600980199873447, 0.0018270299769937992], Test Loss [0.9087728261947632, 1.1957696676254272]
Iteration 1700, Train Loss [0.00334756076335907, 0.0007778294966556132], Test Loss [0.9021621942520142, 1.1940051317214966]
Iteration 1800, Train Loss [0.003907355479896069, 0.0024429375771433115], Test Loss [0.8994554877281189, 1.1925541162490845]
Iteration 1900, Train Loss [0.0018633241998031735, 0.0010938529158011079], Test Loss [0.9012126922607422, 1.1984754800796509]
Iteration 2000, Train Loss [0.0017823566449806094, 0.0014570696512237191], Test Loss [0.8981065154075623, 1.1953781843185425]
Iteration 0, Train Loss [0.593424916267395, 0.5532549023628235], Test Loss [0.5137996673583984, 0.6011491417884827]
Iteration 100, Train Loss [0.03811434656381607, 0.035341907292604446], Test Loss [0.806017279624939, 1.1373639106750488]
Iteration 200, Train Loss [0.015469889156520367, 0.012868468649685383], Test Loss [0.834682047367096, 1.2036906480789185]
Iteration 300, Train Loss [0.01120910793542862, 0.01364859938621521], Test Loss [0.8418993949890137, 1.2287079095840454]
Iteration 400, Train Loss [0.005848012864589691, 0.003972985316067934], Test Loss [0.8449780941009521, 1.2494744062423706]
Iteration 500, Train Loss [0.0038996709045022726, 0.005877647548913956], Test Loss [0.8445088863372803, 1.2514855861663818]
Iteration 600, Train Loss [0.00355145032517612, 0.002749929204583168], Test Loss [0.8404973149299622, 1.2452099323272705]
Iteration 700, Train Loss [0.0031678038649260998, 0.0021838010288774967], Test Loss [0.8415685892105103, 1.242920160293579]
Iteration 800, Train Loss [0.0037154671736061573, 0.002281533321365714], Test Loss [0.8387174010276794, 1.237672209739685]
Iteration 900, Train Loss [0.0029376002494245768, 0.0018446033354848623], Test Loss [0.8379493951797485, 1.2344425916671753]
Iteration 1000, Train Loss [0.002573638455942273, 0.0021659005433321], Test Loss [0.8330893516540527, 1.2254620790481567]
Iteration 1100, Train Loss [0.001191644580103457, 0.0007955168257467449], Test Loss [0.8337551951408386, 1.2216144800186157]
Iteration 1200, Train Loss [0.001204978208988905, 0.0006388796609826386], Test Loss [0.8191829323768616, 1.1998590230941772]
Iteration 1300, Train Loss [0.0010625392897054553, 0.0006045741611160338], Test Loss [0.826280415058136, 1.2062634229660034]
Iteration 1400, Train Loss [0.0006034178659319878, 0.0004424997605383396], Test Loss [0.8247329592704773, 1.201056718826294]
Iteration 1500, Train Loss [0.0031330690253525972, 0.00223002047277987], Test Loss [0.8182118535041809, 1.1918394565582275]
Iteration 1600, Train Loss [0.0066857957281172276, 0.010579705238342285], Test Loss [0.8163455128669739, 1.1740539073944092]
Iteration 1700, Train Loss [0.001037845853716135, 0.0005573348025791347], Test Loss [0.8145205974578857, 1.1865838766098022]
Iteration 1800, Train Loss [0.0024968991056084633, 0.0022683762945234776], Test Loss [0.8083310723304749, 1.178228735923767]
Iteration 1900, Train Loss [0.0073913708329200745, 0.004009142052382231], Test Loss [0.8072074055671692, 1.168676495552063]
Iteration 2000, Train Loss [0.5824938416481018, 0.616376519203186], Test Loss [0.5575270652770996, 1.177431583404541]
Iteration 0, Train Loss [0.5991602540016174, 0.599279522895813], Test Loss [0.6234742999076843, 0.5952021479606628]
Iteration 100, Train Loss [0.019094860181212425, 0.017682701349258423], Test Loss [0.7721987366676331, 1.0172392129898071]
Iteration 200, Train Loss [0.009026794694364071, 0.006643352564424276], Test Loss [0.7908653616905212, 1.059813380241394]
Iteration 300, Train Loss [0.007241225801408291, 0.004656941629946232], Test Loss [0.8002551794052124, 1.0779882669448853]
Iteration 400, Train Loss [0.0039002015255391598, 0.0013803140027448535], Test Loss [0.8003576397895813, 1.0795750617980957]
Iteration 500, Train Loss [0.0034149212297052145, 0.0015556109137833118], Test Loss [0.794895589351654, 1.072089433670044]
Iteration 600, Train Loss [0.002929294016212225, 0.0008739607292227447], Test Loss [0.7927480936050415, 1.0656667947769165]
Iteration 700, Train Loss [0.0013839510502293706, 0.0006787680904380977], Test Loss [0.7848871946334839, 1.0596767663955688]
Iteration 800, Train Loss [0.0023038769140839577, 0.0007276384858414531], Test Loss [0.7790089249610901, 1.0537214279174805]
Iteration 900, Train Loss [0.0012742220424115658, 0.0010543841635808349], Test Loss [0.7747877836227417, 1.0426162481307983]
Iteration 1000, Train Loss [0.000981848337687552, 0.0005576535477302969], Test Loss [0.7695685625076294, 1.0402084589004517]
Iteration 1100, Train Loss [0.0020088038872927427, 0.0006294648628681898], Test Loss [0.7638444900512695, 1.033192753791809]
Iteration 1200, Train Loss [0.0012103649787604809, 0.001157210674136877], Test Loss [0.7603732943534851, 1.025769591331482]
Iteration 1300, Train Loss [0.001164257526397705, 0.00043194094905629754], Test Loss [0.7584900259971619, 1.030285120010376]
Iteration 1400, Train Loss [0.00043455796549096704, 0.000834000064060092], Test Loss [0.7549794316291809, 1.0236502885818481]
Iteration 1500, Train Loss [0.0015235947212204337, 0.0004485477111302316], Test Loss [0.7457742691040039, 1.0206903219223022]
Iteration 1600, Train Loss [0.0036579167935997248, 0.0009868418565019965], Test Loss [0.7416408658027649, 1.0153261423110962]
Iteration 1700, Train Loss [0.000604912405833602, 0.0008048364543356001], Test Loss [0.7452948093414307, 1.0124810934066772]
Iteration 1800, Train Loss [0.0005840753437951207, 0.00030025452724657953], Test Loss [0.7389969825744629, 1.0068044662475586]
Iteration 1900, Train Loss [0.0017654035473242402, 0.000681647565215826], Test Loss [0.7376692295074463, 0.9995889067649841]
Iteration 2000, Train Loss [0.0008538297843188047, 0.0006040156586095691], Test Loss [0.739256739616394, 1.0031983852386475]
Iteration 0, Train Loss [0.5973609685897827, 0.591786801815033], Test Loss [0.712783694267273, 0.6224905848503113]
Iteration 100, Train Loss [0.020805049687623978, 0.017316514626145363], Test Loss [0.818220317363739, 0.9874302744865417]
Iteration 200, Train Loss [0.01096124853938818, 0.006035166326910257], Test Loss [0.8156243562698364, 1.0152044296264648]
Iteration 300, Train Loss [0.010127803310751915, 0.004161974880844355], Test Loss [0.8202800750732422, 1.0158665180206299]
Iteration 400, Train Loss [0.0035803047940135, 0.002282720059156418], Test Loss [0.8203932046890259, 1.0248517990112305]
Iteration 500, Train Loss [0.0028102779760956764, 0.0015714827459305525], Test Loss [0.8183404803276062, 1.0174020528793335]
Iteration 600, Train Loss [0.004808292258530855, 0.0009675221517682076], Test Loss [0.8113241791725159, 1.0093164443969727]
Iteration 700, Train Loss [0.0019024494104087353, 0.0014496512012556195], Test Loss [0.8065256476402283, 1.0009111166000366]
Iteration 800, Train Loss [0.0006847381009720266, 0.00016525293176528066], Test Loss [0.8019981980323792, 0.990765392780304]
Iteration 900, Train Loss [0.0010325845796614885, 0.001118963584303856], Test Loss [0.7976539134979248, 0.9863256216049194]
Iteration 1000, Train Loss [0.0019068579422309995, 0.0005054947105236351], Test Loss [0.7924738526344299, 0.9753510355949402]
Iteration 1100, Train Loss [0.001980660017579794, 0.0013649150496348739], Test Loss [0.7881286144256592, 0.9697636365890503]
Iteration 1200, Train Loss [0.005032242275774479, 0.0021883503068238497], Test Loss [0.7829896807670593, 0.9586331248283386]
Iteration 1300, Train Loss [0.00054166279733181, 0.00019556129700504243], Test Loss [0.78223717212677, 0.9590543508529663]
Iteration 1400, Train Loss [0.0009598078322596848, 0.0006026583141647279], Test Loss [0.7805270552635193, 0.9539833068847656]
Iteration 1500, Train Loss [2.292874336242676, 2.29717755317688], Test Loss [2.232027530670166, 8.696385383605957]
Iteration 1600, Train Loss [0.7079919576644897, 0.651072084903717], Test Loss [0.7095069885253906, 3.077449083328247]
Iteration 1700, Train Loss [0.6168786883354187, 0.5727592706680298], Test Loss [0.6211402416229248, 2.290954351425171]
Iteration 1800, Train Loss [0.5765621662139893, 0.5420101881027222], Test Loss [0.5854945182800293, 1.955191731452942]
Iteration 1900, Train Loss [0.5498797297477722, 0.5227190256118774], Test Loss [0.5668148994445801, 1.7835878133773804]
Iteration 2000, Train Loss [0.5279317498207092, 0.5065464973449707], Test Loss [0.556171178817749, 1.687050223350525]
Iteration 0, Train Loss [0.5885107517242432, 0.6140788197517395], Test Loss [0.7428932189941406, 0.6365681886672974]
Iteration 100, Train Loss [0.02601652406156063, 0.026520680636167526], Test Loss [0.6889452934265137, 0.9131844639778137]
Iteration 200, Train Loss [0.009641040116548538, 0.007084069307893515], Test Loss [0.7065616250038147, 0.9397854208946228]
Iteration 300, Train Loss [0.01711093820631504, 0.005631978623569012], Test Loss [0.699791431427002, 0.9329105019569397]
Iteration 400, Train Loss [0.0013511702418327332, 0.0007535875192843378], Test Loss [0.7046183347702026, 0.9446166157722473]
Iteration 500, Train Loss [0.0064299944788217545, 0.004648152273148298], Test Loss [0.7006112933158875, 0.9411407709121704]
Iteration 600, Train Loss [0.7151564359664917, 0.5724632143974304], Test Loss [0.9075020551681519, 2.238643169403076]
Iteration 700, Train Loss [0.48741304874420166, 0.4579313397407532], Test Loss [0.7108489871025085, 1.5991367101669312]
Iteration 800, Train Loss [0.4119982421398163, 0.4077714681625366], Test Loss [0.723357081413269, 1.715774655342102]
Iteration 900, Train Loss [0.3474522829055786, 0.363704115152359], Test Loss [0.750626266002655, 1.8934001922607422]
Iteration 1000, Train Loss [0.2933313250541687, 0.3231522738933563], Test Loss [0.7717834115028381, 2.0770907402038574]
Iteration 1100, Train Loss [0.24544252455234528, 0.2832016050815582], Test Loss [0.7944676280021667, 2.257861375808716]
Iteration 1200, Train Loss [0.2063678503036499, 0.24986213445663452], Test Loss [0.8259006142616272, 2.434295177459717]
Iteration 1300, Train Loss [0.17627841234207153, 0.22567437589168549], Test Loss [0.8555826544761658, 2.596621513366699]
Iteration 1400, Train Loss [0.15346887707710266, 0.20681069791316986], Test Loss [0.8849546313285828, 2.7342920303344727]
Iteration 1500, Train Loss [0.1353321373462677, 0.1906478852033615], Test Loss [0.9149919748306274, 2.8560333251953125]
Iteration 1600, Train Loss [0.12022114545106888, 0.17514397203922272], Test Loss [0.9419822692871094, 2.9639170169830322]
Iteration 1700, Train Loss [0.10744179785251617, 0.16139332950115204], Test Loss [0.9690892100334167, 3.0532004833221436]
Iteration 1800, Train Loss [0.09636341780424118, 0.1483517438173294], Test Loss [0.9978338479995728, 3.109243631362915]
Iteration 1900, Train Loss [0.08658421784639359, 0.13593444228172302], Test Loss [1.0263774394989014, 3.128899097442627]
Iteration 2000, Train Loss [0.07771624624729156, 0.12420819699764252], Test Loss [1.0584638118743896, 3.138849973678589]
Iteration 0, Train Loss [0.5921903848648071, 0.6384312510490417], Test Loss [0.9549002051353455, 0.6792894601821899]
Iteration 100, Train Loss [0.023234134539961815, 0.02181781642138958], Test Loss [0.6974531412124634, 1.060314416885376]
Iteration 200, Train Loss [0.008032338693737984, 0.006463420111685991], Test Loss [0.7129979729652405, 1.077523112297058]
Iteration 300, Train Loss [0.0021654684096574783, 0.0017208599019795656], Test Loss [0.7165242433547974, 1.0795369148254395]
Iteration 400, Train Loss [0.003833172610029578, 0.0020007253624498844], Test Loss [0.7140820026397705, 1.0762163400650024]
Iteration 500, Train Loss [0.0038857581093907356, 0.0037731945049017668], Test Loss [0.7119325995445251, 1.0643408298492432]
Iteration 600, Train Loss [0.0028860014863312244, 0.0021217798348516226], Test Loss [0.7062296271324158, 1.0568078756332397]
Iteration 700, Train Loss [0.0022068230900913477, 0.0009727039723657072], Test Loss [0.7046849131584167, 1.056005597114563]
Iteration 800, Train Loss [0.004567075986415148, 0.003167913295328617], Test Loss [0.6994775533676147, 1.0411853790283203]
Iteration 900, Train Loss [0.0012168764369562268, 0.0008888693409971893], Test Loss [0.6976798176765442, 1.0365737676620483]
Iteration 1000, Train Loss [2.548990249633789, 5.565084934234619], Test Loss [9.717638969421387, 908.8802490234375]
Iteration 1100, Train Loss [0.720307469367981, 0.7741621136665344], Test Loss [3.423166275024414, 419.4897155761719]
Iteration 1200, Train Loss [0.631770670413971, 0.6207166910171509], Test Loss [2.934007167816162, 379.5975036621094]
Iteration 1300, Train Loss [0.5954770445823669, 0.5656035542488098], Test Loss [2.6767117977142334, 357.2133483886719]
Iteration 1400, Train Loss [0.5739124417304993, 0.534417450428009], Test Loss [2.4908227920532227, 341.1183166503906]
Iteration 1500, Train Loss [0.5583319664001465, 0.5123471021652222], Test Loss [2.3403377532958984, 327.6216125488281]
Iteration 1600, Train Loss [0.5457383394241333, 0.49377691745758057], Test Loss [2.2107510566711426, 314.93829345703125]
Iteration 1700, Train Loss [0.5343950390815735, 0.4761495292186737], Test Loss [2.0988917350769043, 303.02069091796875]
Iteration 1800, Train Loss [0.5231683850288391, 0.45802104473114014], Test Loss [1.9927036762237549, 292.16046142578125]
Iteration 1900, Train Loss [0.5116267800331116, 0.43902719020843506], Test Loss [1.894007682800293, 283.6004333496094]
Iteration 2000, Train Loss [0.5001509189605713, 0.4196995496749878], Test Loss [1.8049458265304565, 279.2679443359375]
Iteration 0, Train Loss [0.5936950445175171, 0.7295923829078674], Test Loss [0.8276169300079346, 0.6997194290161133]
Iteration 100, Train Loss [0.014787607826292515, 0.014120222069323063], Test Loss [0.6704591512680054, 0.9373533129692078]
Iteration 200, Train Loss [0.004614011850208044, 0.005488985683768988], Test Loss [0.6735469698905945, 0.9427818059921265]
Iteration 300, Train Loss [0.002538390690460801, 0.003054601838812232], Test Loss [0.674467921257019, 0.9500817656517029]
Iteration 400, Train Loss [0.0027861809358000755, 0.0044769542291760445], Test Loss [0.6686853170394897, 0.9286114573478699]
Iteration 500, Train Loss [0.0019411531975492835, 0.0021988037042319775], Test Loss [0.6675958633422852, 0.9248396754264832]
Iteration 600, Train Loss [0.0015790454344823956, 0.001844196580350399], Test Loss [0.6654709577560425, 0.9160997867584229]
Iteration 700, Train Loss [0.0020631190855056047, 0.00414908304810524], Test Loss [0.6591833829879761, 0.909548819065094]
Iteration 800, Train Loss [0.0012210768181830645, 0.001073302119038999], Test Loss [0.659210205078125, 0.90156090259552]
Iteration 900, Train Loss [0.00324592599645257, 0.0015365787548944354], Test Loss [0.6519035696983337, 0.8892809152603149]
Iteration 1000, Train Loss [0.00494237570092082, 0.00291070225648582], Test Loss [0.6467152237892151, 0.886853814125061]
Iteration 1100, Train Loss [0.002630646340548992, 0.0026522460393607616], Test Loss [0.6474889516830444, 0.881397008895874]
Iteration 1200, Train Loss [0.0007689432241022587, 0.0006508994847536087], Test Loss [0.6495000123977661, 0.8809800148010254]
Iteration 1300, Train Loss [0.6613171100616455, 1.003387451171875], Test Loss [0.6209166049957275, 33.82097625732422]
Iteration 1400, Train Loss [0.5692430138587952, 0.5602686405181885], Test Loss [0.5613822340965271, 16.053314208984375]
Iteration 1500, Train Loss [0.5603987574577332, 0.5338854193687439], Test Loss [0.5589085221290588, 14.552498817443848]
Iteration 1600, Train Loss [0.5544604659080505, 0.5211513638496399], Test Loss [0.5581594705581665, 13.91038703918457]
Iteration 1700, Train Loss [0.5495731830596924, 0.5125965476036072], Test Loss [0.5587674975395203, 13.574100494384766]
Iteration 1800, Train Loss [0.545172393321991, 0.5057192444801331], Test Loss [0.5597448945045471, 13.397303581237793]
Iteration 1900, Train Loss [0.5410358905792236, 0.49967166781425476], Test Loss [0.5611535906791687, 13.315225601196289]
Iteration 2000, Train Loss [0.5368286967277527, 0.49406754970550537], Test Loss [0.5625044107437134, 13.324224472045898]
Iteration 0, Train Loss [0.5910621285438538, 0.8225592374801636], Test Loss [0.920161783695221, 0.8737125992774963]
Iteration 100, Train Loss [0.018168393522500992, 0.021520383656024933], Test Loss [0.6532948613166809, 0.9691684246063232]
Iteration 200, Train Loss [0.003051251173019409, 0.00297788274474442], Test Loss [0.6595913171768188, 0.9825586676597595]
Iteration 300, Train Loss [0.001204752130433917, 0.0014371457509696484], Test Loss [0.656743586063385, 0.972919762134552]
Iteration 400, Train Loss [0.002857951447367668, 0.0035632881335914135], Test Loss [0.6545286774635315, 0.9525871276855469]
Iteration 500, Train Loss [0.0017791223945096135, 0.001232479582540691], Test Loss [0.6500164270401001, 0.9468492865562439]
Iteration 600, Train Loss [0.000697102106641978, 0.0026896479539573193], Test Loss [0.6474252343177795, 0.9349532127380371]
Iteration 700, Train Loss [0.0015148661332204938, 0.0029962495900690556], Test Loss [0.6430268287658691, 0.9272037148475647]
Iteration 800, Train Loss [0.0015767916338518262, 0.0022579599171876907], Test Loss [0.6366695165634155, 0.9238178730010986]
Iteration 900, Train Loss [0.002689542481675744, 0.0015958085423335433], Test Loss [0.6353270411491394, 0.9116079807281494]
Iteration 1000, Train Loss [0.0007856383454054594, 0.0010646339505910873], Test Loss [0.6333349347114563, 0.907243013381958]
Iteration 1100, Train Loss [0.0010162091348320246, 0.0005910966428928077], Test Loss [0.6315104365348816, 0.913456380367279]
Iteration 1200, Train Loss [0.0012865117751061916, 0.0015782994451001287], Test Loss [0.6267657279968262, 0.9044783115386963]
Iteration 1300, Train Loss [0.006253123749047518, 0.002795508597046137], Test Loss [0.6286538243293762, 0.9062537550926208]
Iteration 1400, Train Loss [1.0649081468582153, 1.2501026391983032], Test Loss [4.236847400665283, 251.2976531982422]
Iteration 1500, Train Loss [0.6630092263221741, 0.5545347332954407], Test Loss [3.0457305908203125, 241.90762329101562]
Iteration 1600, Train Loss [0.6042563915252686, 0.535743772983551], Test Loss [2.654644012451172, 228.8748016357422]
Iteration 1700, Train Loss [0.5814592242240906, 0.526383638381958], Test Loss [2.456728458404541, 221.45680236816406]
Iteration 1800, Train Loss [0.569606363773346, 0.5202869176864624], Test Loss [2.3386547565460205, 216.6094207763672]
Iteration 1900, Train Loss [0.5619838237762451, 0.5158408284187317], Test Loss [2.2613372802734375, 213.30177307128906]
Iteration 2000, Train Loss [0.5564973950386047, 0.5122935175895691], Test Loss [2.210476875305176, 211.3057861328125]
